# 선형 회귀 (Linear Regression)
- 선형 회귀는 양적 반응변수를 예측하는 유용한 도구로, 유용하고 폭넓게 사용되는 방법.
- 많은 통계학습 기법이 선형회귀의 일반화 또는 확장이라 볼 수 있다.
---------------------------------------------------------------------------
## 단순선형회귀
- 하나의 설명변수 X에 기초하여 양적 반응변수 Y를 예측한다.
- X와 Y 사이에 선형적 상관관계가 있다고 가정한다.
### 계수 추정
- 데이터 포인트에 가능한 한 가깝게 되도록 하는 절편과 기울기를 추정한다.
- 추정에 가장 많이 사용되는 방법은 최소제곱법 이다.
- 잔차제곱합(residual sum of squares, RSS)은 실제 반응변수 값과 선형모델에 의해 예측된 값 사이의 차이를 제곱하여 다 더한 값이다.
- 최소제곱법은 RSS를 최소화하는 계수 b0와 b1(절편과 기울기)을 선택한다.
### 계수 추정값의 정확도 평가
- 선형회귀와 확률변수의 평균값 추정 비유는 편향의 개념에서 보면 적절한 것이다.
- b0 hat과 b1 hat의 표준오차는 각각 b0과 b1와 어느 정도 다른지를 말해준다. 
- 시그마의 추정치는 잔차표준오차로 알려져 있으며, RSE = sqrt(RSS/(n-2))로 구해진다.
- 가설검정/귀무가설 H0 : X와 Y 사이에 상관관계가 없다 = H0 : b1=0
- 가설검정/대립가설 H1 : X와 Y 사이에 상관관계가 있다 = H0 : b1!=0
- p-값이 작다는 것은 설명변수와 반응변수 사이에 어떠한 실질적인 상관성이 없는데도 우연에 의해 의미 있는 상관성이 관측될 가능성이 거의 없음을 나타낸다.
- 그러므로 p-값이 작으면 설명변수와 반응변수 사이에 상관성이 있다고 유추할 수 있다.
### 모델의 정확도 평가
- 선형회귀적합의 질은 보통 잔차표준오차(RSE)와 R^2 통계량을 사용하여 평가한다.
- RSE는 오차의 표준편차에 대한 추정값으로, 대략 반응변수 값이 실제 회귀선으로부터 벗어나게 될 평균값을 의미한다.
- 모델을 사용하여 얻은 예측값이 실제 값과 아주 가까우면 RSE는 작을 것이고 모델이 데이터를 잘 적합한다고 할 수 있다.
- R^2은 X를 사용하여 설명될 수 있는 Y의 변동비율을 측정한다.
- R^2이 1에 가까우면 반응변수의 변동 중 많은 부분이 회귀에 의해 설명되었다는 것을 말한다.
- R^2이 0에 가까우면 반응변수의 변동 중 대부분이 회귀에 의해 설명되지 않았다는 것을 말한다.
- 단순선형회귀에서 R^2은 상관계수의 제곱과 동일한다. R^2 = r^2 = (Cor(X, Y))^2
---------------------------------------------------------------------------
## 다중선형회귀
- 반응변수의 변화를 설명하기 위해 두 개 이상의 설명변수를 사용하는 선형회귀모형
### 상관관계 검정
- 반응변수와 설명변수 사이에 상관관계가 있는지는 b1=b2=...=bp=0인지 검사하면 결정할 수 있다.
- 가설검정/귀무가설 H0 : X와 Y 사이에 상관관계가 없다 = H0 : b1=b2=...=bp=0
- 가설검정/대립가설 H1 : X와 Y 사이에 상관관계가 있다 = H0 : 적어도 하나의 bj는 영이 아니다
- F 통계량 : ((SST-SSR)/p) / ((SSR/(n-p-1)) = ((SSE)/p) / ((SSR/(n-p-1))
- 반응변수와 설명변수들 사이에 상관관계가 없는 경우 F 통계량이 1에 매우 가까운 값이라고 할 수 있다.
- 반대로 대립 가설이 참인 경우 F의 기대값은 1보다 크다.
- 개별 t 통계량과 연관된 p-값을 사용하여 변수들과 반응변수 사이에 어떤 상관관계가 있는지 결정한다면 상관관계가 있다고 잘못 결론을 내릴 가능성이 매우 높다. 여기서 F 통계량은 설명변수의 개수를 조정하므로 이런 문제가 없다.
- 만일 p가 n보다 크면, 관측치 수보다 추정할 계수가 더 많아 다중선형회귀 적합을 수행할 수 없다.
### 중요 변수의 결정
- 대부분의 경우 설명변수들의 일부(서브셋)만이 반응변수와 상관관계가 있다.
- 상관성이 있는 설명변수만으로 모델 적합을 수행하기 위해 어느 설명변수가 반응변수와 상관성이 있는지 결정하는 것을 변수선택이라 한다.
- 맬로우즈(Mallows) Cp, AIC(Akaike information criterion), BIC(Bayesian information criterion), 수정된 R^2
- 전진선택법, 후진선택법, 혼합선택법
### 모델 적합
- 설명변수를 바꿔가며 R^2를 계산하고 비교해본다. 누구를 추가하면 R^2 값이 개선되는지 혹은 변화가 미미한지 알아본다.
- 설명변수를 바꿔가며 RSE를 계산하고 비교해본다. 누구를 추가하면 RSE 값이 올라가는지, 증가분이 미미한지 알아본다.
- 설명변수들 간의 시너지 효과 또는 상호작용 효과가 있어 설명변수 일부를 결합하는 것이 어느 하나의 설명변수를 사용하는 것보다 Y값을 크게 만들 수 있다.
---------------------------------------------------------------------------
